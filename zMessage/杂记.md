接口幂等性（查询和删除具有天然幂等性 只需要判断更新及添加操作）

多次调用接口时都应该产生一样的效果或返回一样的结果（一般场景对比支付）

代码逻辑判断

例如加入一个orderId标识订单的唯一性 检测订单是否已经支付过

 使用token机制实现接口幂等性,通用性强的实现方法

   token机制实现步骤:

   \1. 生成全局唯一的token,token放到redis或jvm内存,token会在页面跳转时获取.存放到pageScope中,支付请求提交先获取token

   \2. 提交后后台校验token，执行提交逻辑,提交成功同时删除token，生成新的token更新redis ,这样当第一次提交后token更新了,页面再次提交携带的token是已删除的token后台验证会失败不让提交


   token特点：  要申请，一次有效性，可以限流 

   注意： redis要用删除操作来判断token，删除成功代表token校验通过，如果用select+delete来校验token，存在并发问题，不建议使用 



策略模式和工厂模式的区别

在模式结构上比较相似 但工厂模式是创建型模式 作用是创建对象 而策略模式是行为型模式 作用是让对象在许多行为中选择一种行为

简单工厂模式：将对象的选择创建交给了简单工厂类，客户端只需要输入相应的条件就可以，不用负责对象的创建，但是需要客户端自己调用算法类的方法。但是一旦需要增加新的运算类，比如开根运算，就要去修改简单工厂类。
策略模式：对象的选择创建仍需要自己来做，但是将调用方法的职责交给了策略类。一旦需要增加新的策略需要修改客户端。

因此，简单工厂模式的缺点就是当有新的需求增加时，需要频繁的修改工厂类。只用策略模式，当有新的需求增加时需要修改的是客户端，客户端仍然承担着创建对象的职责，并没有减轻客户端的压力。而将这两种模式结合起来使用，则需要修改 Context 类，总之不是完美的。

工厂模式中只管生产实例，具体怎么使用工厂实例由调用方决定，策略模式是将生成实例的使用策略放在策略类中配置后才提供调用方使用。 工厂模式调用方可以直接调用工厂实例的方法属性等，策略模式不能直接调用实例的方法属性，需要在策略类中封装策略后调用。

@ControllerAdvice ，很多初学者可能都没有听说过这个注解，实际上，这是一个非常有用的注解，顾名思义，这是一个增强的 Controller。使用这个 Controller ，可以实现三个方面的功能：

1. 全局异常处理

需要配合@ExceptionHandler使用。

1. 全局数据绑定

使用 @ModelAttribute 注解标记该方法的返回数据是一个全局数据，默认情况下，这个全局数据的 key 就是返回的变量名，value 就是方法返回值，当然开发者可以通过 @ModelAttribute 注解的 name 属性去重新指定 key。

1. 全局数据预处理



怎么解决跨域？很简单，只需要在controller类上添加注解
@CrossOrigin 即可  



7个HTTP方法：GET/POST/PUT/DELETE/PATCH/HEAD/OPTIONS  

delete 不安全但幂等  

put 不安全但幂等  

post 不安全且不幂等  

get 安全且幂等  



forward 转发   redirect重定向

请求的转发和重定向的区别

本质区别：请求的转发只发出了一次请求，而重定向则发出了两次请求

具体的区别体现在：

 1.请求的转发：地址栏是初次发出请求的地址。

   请求的重定向：地址栏不是初次发出请求的地址，为最后响应的地址。

 2.请求转发：在最终的Servlet中，request和中转的那个request是同一个对象。

   请求的重定向：在最终的Servlet中，request和中转的那个request不是同一个对象。

 3.请求转发：只能转发给当前web应用的资源。

  请求的重定向：可以重定向到任何资源。

 4.请求的转发：/代表的是当前web应用的根目录。

  请求的重定向：/代表的是当前web站点的根目录。

RedisTemplate  

redis设置过期时间

redisTemplate.opsForValue().set("article_" + id, article,1,
TimeUnit.DAYS);
redisTemplate.opsForValue().set("article_" + id, article,10,
TimeUnit.SECONDS)  



Spring Cache使用方法与Spring对事务管理的配置相似。Spring Cache的核心就是对某
个方法进行缓存，其实质就是缓存该方法的返回结果，并把方法参数和结果用键值对的
方式存放到缓存中，当再次调用该方法使用相应的参数时，就会直接从缓存里面取出指
定的结果进行返回。
常用注解：

@Cacheable-------使用这个注解的方法在执行后会缓存其返回结果。
@CacheEvict--------使用这个注解的方法在其执行前或执行后移除Spring Cache中的某些
元素  



MongoDB 是一个跨平台的，面向文档的数据库，是当前 NoSQL 数据库产品中最热
门 的
一种。它介于关系数据库和非关系数据库之间，是非关系数据库当中功能最丰富，最
像关
系数据库的产品。它支持的数据结构非常松散，是类似 JSON 的 BSON 格式，因此可以
存 储
比较复杂的数据类型。  

MongoDB 最大的特点是他支持的查询语言非常强大，其语法有点类似于面向对象
的查
询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建
立索
引。它是一个面向集合的,模式自由的文档型数据库。
具体特点总结如下：
（1）面向集合存储，易于存储对象类型的数据
（2）模式自由
（3）支持动态查询
（4）支持完全索引，包含内部对象
（5）支持复制和故障恢复
（6）使用高效的二进制数据存储，包括大型对象（如视频等）
（7）自动处理碎片，以支持云计算层次的扩展性
（8）支持 Python，PHP，Ruby，Java，C，C#，Javascript，Perl 及 C++语言的驱动程
序，
社区中也提供了对 Erlang 及.NET 等平台的驱动程序
（9） 文件存储格式为 BSON（一种 JSON 的扩展）  



MongoDB 的逻辑结构是一种层次结构。主要由：
文档(document)、集合(collection)、数据库(database)这三部分组成的。逻辑结构是面
向用户的，用户使用 MongoDB 开发应用程序使用的就是逻辑结构。
（1）MongoDB 的文档（document），相当于关系数据库中的一行记录。
（2）多个文档组成一个集合（collection），相当于关系数据库的表。
（3）多个集合（collection），逻辑上组织在一起，就是数据库（database）。
（4）一个 MongoDB 实例支持多个数据库（database）。
文档(document)、集合(collection)、数据库(database)的层次结构如下图:  

MongoClient client=new MongoClient("192.168.184.134");//创建连接
MongoDatabase spitdb = client.getDatabase("spitdb");//打开数据库
MongoCollection<Document> spit = spitdb.getCollection("spit");//
获取集合  

mongodb常用命令

使用MongoTemplate类来实现对某列的操作  



Logstash是一款轻量级的日志搜集处理框架，可以方便的把分散的、多样化的日志搜集
起来，并进行自定义的处理，然后传输到指定的位置，比如某个服务器或者文件。  



消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量
削锋等问题实现高性能，高可用，可伸缩和最终一致性[架构] 使用较多的消息队列有
ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ  



RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。
AMQP ：Advanced Message Queue，高级消息队列协议。它是应用层协议的一个开放
标准，为面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不
受产品、开发语言等条件的限制。
RabbitMQ 最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展
性、高可用性等方面表现不俗。具体特点包括：
1.可靠性（Reliability）
RabbitMQ 使用一些机制来保证可靠性，如持久化、传输确认、发布确认。
2.灵活的路由（Flexible Routing）
在消息进入队列之前，通过 Exchange 来路由消息的。对于典型的路由功能，RabbitMQ
已经提供了一些内置的 Exchange 来实现。针对更复杂的路由功能，可以将多个
Exchange 绑定在一起，也通过插件机制实现自己的 Exchange 。
3.消息集群（Clustering）
多个 RabbitMQ 服务器可以组成一个集群，形成一个逻辑 Broker 。
4.高可用（Highly Available Queues）
队列可以在集群中的机器上进行镜像，使得在部分节点出问题的情况下队列仍然可用。
5.多种协议（Multi-protocol）
RabbitMQ 支持多种消息队列协议，比如 STOMP、MQTT 等等。
6.多语言客户端（Many Clients）
RabbitMQ 几乎支持所有常用语言，比如 Java、.NET、Ruby 等等。
7.管理界面（Management UI）
RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息 Broker 的许多方
面。
8.跟踪机制（Tracing）
如果消息异常，RabbitMQ 提供了消息跟踪机制，使用者可以找出发生了什么。
9.插件机制（Plugin System）
RabbitMQ 提供了许多插件，来从多方面进行扩展，也可以编写自己的插件。  



JJWT是一个提供端到端的JWT创建和验证的Java库。永远免费和开源(Apache
License，版本2.0)，JJWT很容易使用和理解。它被设计成一个以建筑为中心的流畅界
面，隐藏了它的大部分复杂性  

setIssuedAt用于设置签发时间
signWith用于设置签名秘钥  

setExpiration 方法用于设置过期时间  

测试运行，当未过期时可以正常读取，当过期时会引发
io.jsonwebtoken.ExpiredJwtException异常。  

我们刚才已经创建了token ，在web应用中这个操作是由服务端进行然后发给客户
端，客户端在下次向服务端发送请求时需要携带这个token（这就好像是拿着一张门票一
样），那服务端接到这个token 应该解析出token中的信息（例如用户id）,根据这些信息
查询数据库返回相应的结果。  

我们刚才的例子只是存储了id和subject两个信息，如果你想存储更多的信息（例如角
色）可以定义自定义claims  

如果我们每个方法都去写一段代码，冗余度太高，不利于维护，那如何做使我们的代码
看起来更清爽呢？我们可以将这段代码放入拦截器去实现  

Spring为我们提供了
org.springframework.web.servlet.handler.HandlerInterceptorAdapter这个适配器，
继承此类，可以非常方便的实现自己的拦截器。他有三个方法：
分别实现预处理、后处理（调用了Service并返回ModelAndView，但未进行页面渲
染）、返回处理（已经渲染了页面）
在preHandle中，可以进行编码、安全控制等处理；
在postHandle中，有机会修改ModelAndView；
在afterCompletion中，可以根据ex是否为null判断是否发生了异常，进行日志记录。  



RestTemplate： 是 Spring 提供的用于访问Rest服务的客户端， RestTemplate 提供了多种便捷访问远程Http服务的方法,能够大大提高客户端的编写效率。



httpclient方法

请求行 :请求方法 url http版本

请求头 : header

请求体: entity

```java
// 模拟表单
List<NameValuePair> paramList = new ArrayList<>();
                for (String key : param.keySet()) {
                    paramList.add(new BasicNameValuePair(key, param.get(key).toString()));
                }
UrlEncodedFormEntity entity = new UrlEncodedFormEntity(paramList,Consts.UTF_8);
httpPost.setEntity(entity);

//模拟json
 StringEntity entity = new StringEntity(jsonString,"utf-8");
 entity.setContentEncoding("UTF-8");
 entity.setContentType("application/json");
 httpPost.setEntity(entity);
```

```java
//配置
httpPost.setConfig(proConfig);
//执行请求
response = httpClient.execute(targetHost,httpPost,context);
```

```java
//返回内容
resultString = EntityUtils.toString(response.getEntity(), "utf-8");
```



httpclient使用http连接池 PoolingHttpClientConnectionManager解决httpclient的多线程请求问题

如果单独使用一个请求 类似doGet方法 当多个线程发起请求时会出现问题

http1.1默认开启keep-alive

httpclient使用代理模式 设置连接超时时间 响应超时间



项目中遇到的问题

# HttpClient偶尔报NoHttpResponseException: xxx failed to respond

这个只会在服务器端keep-alive刚好过期的时间我们进行访问才能大概率复现

可以在httpclient的excute方法后加加入一个sleep可以模拟这个问题

解决这个问题的最好办法是加入重试机制(retry)

三次握手四次挥手

三次握手:1. 客户端发送初始序号x和SYN=1请求标志(建立联机)

2.服务器发送请求标识SYN和确认标志ACK,发送自己的序号seq =y，发送客户端的确认序号ack=x+1

3.客户端发送ACK确认号，发送自己的序号seq=x+1，发送对方的确认号ack=y+1

四次挥手:

- 第一次挥手：客户端发出释放FIN=1，自己序列号seq=u，进入FIN-WAIT-1状态
- 第二次挥手：服务器收到客户端的后，发出ACK=1确认标志和客户端的确认号ack=u+1，自己的序列号seq=v，进入CLOSE-WAIT状态
- 第三次挥手：客户端收到服务器确认结果后，进入FIN-WAIT-2状态。此时服务器发送释放FIN=1信号，确认标志ACK=1，确认序号ack=u+1，自己序号seq=w，服务器进入LAST-ACK（最后确认态）
- 第四次挥手：客户端收到回复后，发送确认ACK=1，ack=w+1，自己的seq=u+1，客户端进入TIME-WAIT（时间等待）。客户端经过2个最长报文段寿命后，客户端CLOSE；服务器收到确认后，立刻进入CLOSE状态。



synchronized 和 ReentrantLock 的区别
4.1.19.1. 两者的共同点：
\1. 都是用来协调多线程对共享对象、变量的访问
\2. 都是可重入锁，同一线程可以多次获得同一个锁
\3. 都保证了可见性和互斥性
121623125152125125
4.1.19.2. 两者的不同点：
\1. ReentrantLock 显示的获得、释放锁， synchronized 隐式获得释放锁
\2. ReentrantLock 可响应中断、可轮回， synchronized 是不可以响应中断的，为处理锁的
不可用性提供了更高的灵活性
\3. ReentrantLock 是 API 级别的， synchronized 是 JVM 级别的
\4. ReentrantLock 可以实现公平锁
\5. ReentrantLock 通过 Condition 可以绑定多个条件
\6. 底层实现不一样， synchronized 是同步阻塞，使用的是悲观并发策略， lock 是同步非阻
塞，采用的是乐观并发策略
\7. Lock 是一个接口，而 synchronized 是 Java 中的关键字， synchronized 是内置的语言
实现。
\8. synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；
而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁，则很可能造成死锁现象，
因此使用 Lock 时需要在 finally 块中释放锁。
\9. Lock 可以让等待锁的线程响应中断，而 synchronized 却不行，使用 synchronized 时，
等待的线程会一直等待下去，不能够响应中断。
\10. 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。
\11. Lock 可以提高多个线程进行读操作的效率，既就是实现读写锁等。  



maven

Dependencies：是可选依赖（Optional Dependencies） 
Exclusions：是依赖排除（Dependency Exclusions） 



NIO 和传统 IO 之间第一个最大的区别是， IO 是面向流的， NIO 是面向缓冲区的。  



简单理解就是， ConcurrentHashMap 是一个 Segment 数组， Segment 通过继承
ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每
个 Segment 是线程安全的，也就实现了全局的线程安全。  

concurrencyLevel：并行级别、并发数、 Segment 数，怎么翻译不重要，理解它。默认是 16，
也就是说 ConcurrentHashMap 有 16 个 Segments，所以理论上， 这个时候，最多可以同时支
持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment 上。这个值可以在初始化的时
候设置为其他值，但是一旦初始化以后，它是不可以扩容的。再具体到每个 Segment 内部，其实
每个 Segment 很像之前介绍的 HashMap，不过它要保证线程安全，所以处理起来要麻烦些。  



java 中的乐观锁基本都是通过 CAS 操作实现的， CAS 是一种更新的原子操作， 比较当前值跟传入
值是否一样，一样则更新，否则失败  

java中的悲观锁就是Synchronized,AQS框架下的锁则是先尝试cas乐观锁去获取锁，获取不到，
才会转换为悲观锁，如 RetreenLock。  

synchronized 它可以把任意一个非 NULL 的对象当作锁。 他属于独占式的悲观锁，同时属于可重
入锁。  



synchronized实现

\1. JVM 每次从队列的尾部取出一个数据用于锁竞争候选者（OnDeck），但是并发情况下，
ContentionList 会被大量的并发线程进行 CAS 访问，为了降低对尾部元素的竞争， JVM 会将
一部分线程移动到 EntryList 中作为候选竞争线程。
\2. Owner 线程会在 unlock 时，将 ContentionList 中的部分线程迁移到 EntryList 中，并指定
EntryList 中的某个线程为 OnDeck 线程（一般是最先进去的那个线程）。
\3. Owner 线程并不直接把锁传递给 OnDeck 线程，而是把锁竞争的权利交给 OnDeck，
OnDeck 需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在
JVM 中，也把这种选择行为称之为“竞争切换”。
\4. OnDeck 线程获取到锁资源后会变为 Owner 线程，而没有得到锁资源的仍然停留在 EntryList
中。如果 Owner 线程被 wait 方法阻塞，则转移到 WaitSet 队列中，直到某个时刻通过 notify
或者 notifyAll 唤醒，会重新进去 EntryList 中。
\5. 处于 ContentionList、 EntryList、 WaitSet 中的线程都处于阻塞状态，该阻塞是由操作系统
来完成的（Linux 内核下采用 pthread_mutex_lock 内核函数实现的）。
\6. Synchronized 是非公平锁。 Synchronized 在线程进入 ContentionList 时， 等待的线程会先
尝试自旋获取锁，如果获取不到就进入 ContentionList，这明显对于已经进入队列的线程是
不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占 OnDeck 线程的锁
资源。
参考： https://blog.csdn.net/zqz_zqz/article/details/70233767
\7. 每个对象都有个 monitor 对象， 加锁就是在竞争 monitor 对象，代码块加锁是在前后分别加
上 monitorenter 和 monitorexit 指令来实现的，方法加锁是通过一个标记位来判断的
\8. synchronized 是一个重量级操作，需要调用操作系统相关接口，性能是低效的，有可能给线
程加锁消耗的时间比有用操作消耗的时间更多。
\9. Java1.6， synchronized 进行了很多的优化， 有适应自旋、锁消除、锁粗化、轻量级锁及偏向
锁等，效率有了本质上的提高。在之后推出的 Java1.7 与 1.8 中，均对该关键字的实现机理做
了优化。引入了偏向锁和轻量级锁。都是在对象头中有标记位，不需要经过操作系统加锁。
\10. 锁可以从偏向锁升级到轻量级锁，再升级到重量级锁。这种升级过程叫做锁膨胀；
\11. JDK 1.6 中默认是开启偏向锁和轻量级锁，可以通过-XX:-UseBiasedLocking 来禁用偏向锁  



Synchronized 是通过对象内部的一个叫做监视器锁（monitor）来实现的。但是监视器锁本质又
是依赖于底层的操作系统的 Mutex Lock 来实现的。而操作系统实现线程之间的切换这就需要从用
户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么
Synchronized 效率低的原因。因此， 这种依赖于操作系统 Mutex Lock 所实现的锁我们称之为
“重量级锁” 。 JDK 中对 Synchronized 做的种种优化，其核心都是为了减少这种重量级锁的使用。
JDK1.6 以后，为了减少获得锁和释放锁所带来的性能消耗，提高性能，引入了“轻量级锁”和
“偏向锁”。  

锁升级
随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁（但是锁的升级是单向的，
也就是说只能从低到高升级，不会出现锁的降级）。  



java 并发包提供的加锁模式分为独占锁和共享锁。
独占锁
独占锁模式下，每次只能有一个线程能持有锁， ReentrantLock 就是以独占方式实现的互斥锁。
独占锁是一种悲观保守的加锁策略，它避免了读/读冲突，如果某个只读线程获取锁，则其他读线
程都只能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。
共享锁
共享锁则允许多个线程同时获取锁，并发访问 共享资源，如： ReadWriteLock。 共享锁则是一种
乐观锁，它放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源  



最常见的锁分离就是读写锁 ReadWriteLock，根据功能进行分离成读锁和写锁，这样读读不互
斥，读写互斥，写写互斥，即保证了线程安全，又提高了性能，具体也请查看[高并发 Java 五]
JDK 并发包 1。读写分离思想可以延伸，只要操作互不影响，锁就可以分离。比如
LinkedBlockingQueue 从头部取出，从尾部放数据  



java内存模型

关于主内存与工作内存之间的具体交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步到主内存之间的实现细节，Java内存模型定义了以下八种操作来完成：

- **lock（锁定）**：作用于主内存的变量，把一个变量标识为一条线程独占状态。
- **unlock（解锁）**：作用于主内存变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。
- **read（读取）**：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用
- **load（载入）**：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。
- **use（使用）**：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。
- **assign（赋值）**：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。
- **store（存储）**：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。
- **write（写入）**：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。

Java内存模型还规定了在执行上述八种基本操作时，必须满足如下规则：

- 如果要把一个变量从主内存中复制到工作内存，就需要按顺寻地执行read和load操作， 如果把变量从工作内存中同步回主内存中，就要按顺序地执行store和write操作。但Java内存模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行。 
- 不允许read和load、store和write操作之一单独出现
- 不允许一个线程丢弃它的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中。
- 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中。
- 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。
- 一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。lock和unlock必须成对出现
- 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值 
- 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。
- 对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）。 



ThreadLocal，很多地方叫做线程本地变量，也有些地方叫做线程本地存储， ThreadLocal 的作用
是提供线程内的局部变量， 这种变量在线程的生命周期内起作用， 减少同一个线程内多个函数或
者组件之间一些公共变量的传递的复杂度。  



shiro

shiro中

SecurityManager（安全管理器）：

 可以理解成控制中心，所有请求最终基本上都通过它来代理转发，一般我们程序中不需要直接跟他打交道。

realm (自己理解是认证授权的东西)  ：

这个实在不知道怎么翻译合适。通俗一点理解就是realm可以访问安全相关数据，提供统一的数据封装来给上层做数据校验。shiro的建议是每种数据源定义一个realm，比如用户数据存在数据库可以使用JdbcRealm；存在属性配置文件可以使用PropertiesRealm。一般我们使用shiro都使用自定义的realm。
 当有多个realm存在的时候，shiro在做用户校验的时候会按照定义的策略来决定认证是否通过，shiro提供的可选策略有一个成功或者所有都成功等。
 一个realm对应了一个CredentialsMatcher，用来做用户提交认证信息和realm获取得用户信息做比对，shiro已经提供了常用的比如用户密码和存储的Hash后的密码的对比

subject（请求主体） ：

比如登录用户，比如一个被授权的app。在程序中任何地方都可以通过`SecurityUtils.getSubject()`获取到当前的subject。subject中可以获取到Principal，这个是subject的标识，比如登陆用户的用户名或者id等，shiro不对值做限制。但是在登录和授权过程中，程序需要通过principal来识别唯一的用户。

CredentialsMatcher是凭证校验匹配器， 用来做用户提交认证信息和realm获取得用户信息做比对，shiro已经提供了常用的比如用户密码和存储的Hash后的密码的对比

Subject.login(AuthenticationToken)方法，即为shiro的认证方法，这里参数传入的是一个AuthenticationToken对象，查看源码可知Subject的登录将委托给SecurityManager，SecurityManager的login方法实际上是产生了一个新的Subject，然后将相关属性赋予当前调用者Subject

login方法传入的参数如果是自己重写的AuthenticationToken类型对象 因为源码中doSingleRealmAuthentication方法（ps:这里会根据有多少个realm分别进入单个和多个的判断方法）会对realm的类型进行判断也就是调用supports方法，所以在自己自定义realm类中必须重写这个supports方法（不重写会报类型不匹配的错误）,让AuthenticationToken类型指向自己定义的类型，源码继续往下走就会进入到自己定义的realm类中（自己重写的类在shiro源码中在getAuthenticationInfo方法中被调用，这个方法调用完之后还会继续往下走，进行凭证校验匹配器的判断），进入到doGetAuthenticationInfo认证方法中然后创建一个SimpleAuthenticationInfo对象，源码继续往下走会进入到一个assertCredentialsMatch方法中，这个方法会获取当前的CredentialsMatcher，如果在shiroConfig中重写了setCredentialsMatcher方法，当前即会获取重写的CredentialsMatcher对象，然后进行重写的策略进行加密，然后判断加密生成的和原本生成的AuthenticationToken对象是否一样(调用equal方法)，所以在这里注意如果使用的是自定义token而不是系统自带的UsernamePasswordToken方法生成的token（HostAuthenticationToken对象），不要重复的重写CredentialsMatcher对象

首先创建一个SecurityManager

shiro自定义一个filter，filter继承BasicHttpAuthenticationFilter



```java

ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean();

// 添加自己的过滤器并且取名为jwt
Map<String, Filter> filterMap = new LinkedHashMap<>();
//设置我们自定义的JWT过滤器
filterMap.put("jwt", new JWTFilter());

//给filter设置安全管理器
shiroFilterFactoryBean.setSecurityManager(securityManager);
shiroFilterFactoryBean.setFilters(filterMap);
Map<String, String> filterChainDefinitionMap = new HashMap<String,String>();
//map.put("/user/login","anon");
filterChainDefinitionMap.put("/**","jwt");
shiroFilterFactoryBean.setFilterChainDefinitionMap(filterChainDefinitionMap);
```







